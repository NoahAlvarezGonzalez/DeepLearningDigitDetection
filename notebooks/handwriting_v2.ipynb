{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the mnist dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Load the dataset into variable for further processing\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train\", type(X_train))\n",
    "print(\"y_train\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc\n",
    "# 2DConv need 4dim input\n",
    "# Add 4th empty dim to our input\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster training when dtype is float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the feature\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "  # Init a sequential model\n",
    "  model = keras.Sequential([\n",
    "    \n",
    "\n",
    "    # Feature detector\n",
    "\n",
    "    # First VGG block\n",
    "    # Hidden layer 1: 32 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1), kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(), # more stable model\n",
    "      \n",
    "    # Hidden layer 2: 32 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "\n",
    "    # Second VGG block\n",
    "    # Hidden layer 3: 64 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Hidden layer 4: 64 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "\n",
    "    # Third VGG block\n",
    "    # Hidden layer 5: 128 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Hidden layer 6: 128 filters, 3x3 kernel, relu activation function\n",
    "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Flatten(),\n",
    "\n",
    "\n",
    "    # Part 2: classifier\n",
    "\n",
    "    # Simple ANN\n",
    "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(10, activation='softmax')\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Compile model \n",
    "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# increase the diversity of data available for training models\n",
    "# without actually collecting new data\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=360)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "augmented_train = datagen.flow(X_train, y_train, batch_size=64)\n",
    "steps = int(X_train.shape[0] / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(augmented_train, steps_per_epoch=steps, epochs=20, \n",
    "                              validation_data=(X_test,y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
